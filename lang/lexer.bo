module lexer

import ../std/io
import ../std/strings
import ../std/chars

type Token {
    null
    TokOp(string)
    TokInt(i64)
    TokSym(char)
    TokIdent(string)
    TokString(string)
    TokChar(char)
    TokKeyword(string)
}

fn string(token Token) string
    switch token 
        null         ; return "null"
        TokOp(s)     ; return "TokOp: " + s
        TokInt(n)    ; return "TokInt: " + string(n)
        TokSym(c)    ; return "TokSym: " + [c]
        TokString(s) ; return "TokString: " + s
        TokChar(c)   ; return "TokChar: " + [c]
        TokIdent(s)  ; return "TokIdent: " + s
        TokKeyword(s); return "TokKeyword: " + s

fn ==(a Token, b Token) bool
    switch (a, b)
        (null, null)                   ; return true
        (TokOp(a),      TokOp(b))      ; return a == b
        (TokInt(a),     TokInt(b))     ; return a == b
        (TokSym(a),     TokSym(b))     ; return a == b
        (TokIdent(a),   TokIdent(b))   ; return a == b
        (TokString(a),  TokString(b))  ; return a == b
        (TokChar(a),    TokChar(b))    ; return a == b
        (TokKeyword(a), TokKeyword(b)) ; return a == b
        _                              ; return false



let keywords  = ["let", "while", "fn", "extern", "true", "false", "null", "if", "else", "return", "module", "imports", "append"]
let types     = ["i8", "i16", "i32", "i64", "char", "bool", "string"]
let operators = ["+", "-", "*", "/", "%", "=", "+=", "-=", "*=", "/=", "%=", "..", "<", ">", "<=", ">=", "&&", "||", "=="]
let symbols   = ['(', ')', '[', ']', '{', '}', ':', ';', '.', ',']

fn lexChar(str string) (Token, string)
    switch str
        "'\\n'" ->> ss         ; return (TokChar('\n'), ss)
        "'\\0'" ->> ss         ; return (TokChar('\0'), ss)
        "'\\t'" ->> ss         ; return (TokChar('\t'), ss)
        "'\\'" ->> ss          ; return (TokChar('\\'), ss)
        "'\n" ->> ss           ; return (null, str)
        "'\t" ->> ss           ; return (null, str)
        '\'' -> c -> '\'' -> ss; return (TokChar(c), ss)
        _                      ; return (null, str)


fn lexString(str string) (Token, string)
    if !strings::isPrefix("\"", str)
        return (null, str)

    let s = ""
    let rest = str[1..]

    while true
        switch rest
            "\n"  ->> ss; return (null, str)
            "\"" ->> ss ; return (TokString(s), ss)
            "\\n" ->> ss
                s <- '\n'
                rest = ss
            "\\0" ->> ss
                s <- '\0'
                rest = ss
            "\\t" ->> ss
                s <- '\t'
                rest = ss
            c -> ss
                s <- c
                rest = ss


fn lexSymbol(str string) (Token, string)
    if str: c -> s
        for [i] symbols
            if c == symbols[i]
                return (TokSym(c), s)

    return (null, str)


fn lexKeyword(str string) (Token, string)
    let (i, k) = (0, 0)

    while str[i..]: c -> ss | isAlpha(c)
        i = i + 1

    let word = str[..i]
    for [k] keywords
        if word == keywords[k]
            return (TokKeyword(word), str[i..])

    return (null, str)

fn lexDigits(str string) (Token, string)
    let i = 0
    while str[i..]: c -> ss | isDigit(c)
        i = i + 1
 
    switch strReadInt(str[..i])
        (n, true) ; return (TokInt(n), str[i..])
        (_, false); return (null, str)


fn lexIdent(str string) (Token, string)
    if str: c -> ss | isAlpha(c)
        let i = 0
        while str[i..]: c -> ss | isAlpha(c) || isDigit(c)
            i = i + 1
        return (TokIdent(str[..i]), str[i..])

    return (null, str)


fn lexOperator(str string) (Token, string)
    let op = ""

    for [i] operators
        if strings::isPrefix(operators[i], str) && len(operators[i]) > len(op)
            op = operators[i]
        
    switch len(op)
        0; return (null, str)
        n; return (TokOp(op),  str[n..])


fn lexWhite(str string) string
    for [i] str
        if str[i] != ' ' && str[i] != '\t' && str[i] != '\n'
            return str[..i]

    return ""


fn lexToken(str string) (Token, string)
    if lexWhite(str): s | len(s) > 0
        return lexToken(str[len(s)..])

    let fns = [lexKeyword, lexString, lexChar, lexIdent, lexOperator, lexDigits, lexSymbol]
    for [i] fns
        switch fns[i](str)
            (null, _);
            (tok, ss); return (tok, ss)

    return (null, str)


fn lexTokens(str string) ([Token], string)
    let toks = :[Token]()

    while true
        switch lexToken(str)
            (null, _); return (toks, str)
            (tok, ss)
                str = ss
                toks <- tok
